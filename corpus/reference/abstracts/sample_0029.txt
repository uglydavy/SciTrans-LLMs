Cet article présente une nouvelle approche de la traduction automatique utilisant des mécanismes d'attention. Nous démontrons que notre méthode atteint des performances de pointe sur les benchmarks standards.

Nos expériences montrent une amélioration de 8% par rapport aux approches de référence. L'algorithme proposé a une complexité temporelle O(n log n) et une complexité spatiale O(n).

Nous validons notre approche sur le jeu de données X, atteignant un score BLEU de 44. Les travaux futurs exploreront les applications à X.